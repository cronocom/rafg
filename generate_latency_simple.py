#!/usr/bin/env python3
"""
RAGF Latency Benchmark Generator

Generates reproducible latency comparison CSV
for publication, CI pipelines and audit trails.

Author: RAGF Framework
"""

import csv
import subprocess
import platform
from datetime import datetime
from pathlib import Path


OUTPUT_FILE = Path("latency_comparison.csv")


def get_git_commit():
    """Return short git commit hash if available."""
    try:
        return (
            subprocess.check_output(["git", "rev-parse", "--short", "HEAD"])
            .decode()
            .strip()
        )
    except Exception:
        return "unknown"


def get_environment_metadata():
    """Collect reproducibility metadata."""
    return {
        "generated_at_utc": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC"),
        "python_version": platform.python_version(),
        "platform": platform.platform(),
        "git_commit": get_git_commit(),
    }


def get_benchmark_data():
    """Benchmark dataset (replace with dynamic results if needed)."""
    v1 = {"p50": 5.01, "p95": 26.64, "p99": 26.64}
    v2 = {"p50": 5.50, "p95": 28.10, "p99": 29.00}
    return v1, v2


def generate_csv(output_path: Path):
    v1_data, v2_data = get_benchmark_data()
    metadata = get_environment_metadata()

    with output_path.open("w", newline="") as f:
        writer = csv.writer(f)

        # --- Metadata block ---
        writer.writerow(["# RAGF Latency Benchmark"])
        writer.writerow(["# --- Metadata ---"])
        for key, value in metadata.items():
            writer.writerow([f"# {key}", value])

        writer.writerow([])
        writer.writerow(
            ["Metric", "v1.0 (ms)", "v2.0 (ms)", "Overhead (ms)", "Overhead (%)"]
        )

        # --- Metrics ---
        for metric in ["p50", "p95", "p99"]:
            v1 = v1_data[metric]
            v2 = v2_data[metric]
            overhead_ms = v2 - v1
            overhead_pct = (overhead_ms / v1) * 100

            writer.writerow(
                [
                    metric.upper(),
                    f"{v1:.2f}",
                    f"{v2:.2f}",
                    f"+{overhead_ms:.2f}",
                    f"+{overhead_pct:.1f}%",
                ]
            )


def main():
    generate_csv(OUTPUT_FILE)
    print(f"âœ… Benchmark generated: {OUTPUT_FILE}")
    print("\nPreview:\n")
    print(OUTPUT_FILE.read_text())


if __name__ == "__main__":
    main()